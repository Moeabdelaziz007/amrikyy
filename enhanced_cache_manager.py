#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Advanced Cache Management System for AuraOS Learning Growth
Ù†Ø¸Ø§Ù… Ù…ØªÙ‚Ø¯Ù… Ù„Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù…Ø¤Ù‚Øª ÙˆØªØ¬Ù†Ø¨ Ø§Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ø²Ø§Ø¦Ø¯
"""

import asyncio
import json
import time
import hashlib
import heapq
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional, Tuple, Union
from collections import defaultdict, OrderedDict
from dataclasses import dataclass, field
from enum import Enum
import logging
import psutil
import os

# Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØªØ³Ø¬ÙŠÙ„
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class CacheType(Enum):
    """Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù…Ø¤Ù‚Øª"""
    PATTERN_CACHE = "pattern_cache"
    RESPONSE_CACHE = "response_cache"
    CONTEXT_CACHE = "context_cache"
    LEARNING_CACHE = "learning_cache"
    METRICS_CACHE = "metrics_cache"

class EvictionPolicy(Enum):
    """Ø³ÙŠØ§Ø³Ø§Øª Ø§Ù„Ø¥Ø²Ø§Ù„Ø©"""
    LRU = "lru"  # Least Recently Used
    LFU = "lfu"  # Least Frequently Used
    TTL = "ttl"  # Time To Live
    SIZE_BASED = "size_based"
    ADAPTIVE = "adaptive"

@dataclass
class CacheEntry:
    """Ø¥Ø¯Ø®Ø§Ù„ Ø§Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù…Ø¤Ù‚Øª"""
    key: str
    value: Any
    cache_type: CacheType
    created_at: datetime
    last_accessed: datetime
    access_count: int = 0
    size_bytes: int = 0
    ttl_seconds: Optional[int] = None
    priority: float = 1.0
    metadata: Dict[str, Any] = field(default_factory=dict)

@dataclass
class CacheStats:
    """Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù…Ø¤Ù‚Øª"""
    total_entries: int
    total_size_bytes: int
    hit_rate: float
    miss_rate: float
    eviction_count: int
    memory_usage_percent: float
    cache_efficiency: float

class AdvancedCacheManager:
    """Ù…Ø¯ÙŠØ± Ø§Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù…Ø¤Ù‚Øª Ø§Ù„Ù…ØªÙ‚Ø¯Ù…"""
    
    def __init__(self):
        self.caches: Dict[CacheType, Dict[str, CacheEntry]] = {
            cache_type: {} for cache_type in CacheType
        }
        
        # Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ù†Ø¸Ø§Ù…
        self.config = {
            "max_total_size_mb": 100,
            "max_entries_per_cache": 1000,
            "default_ttl_seconds": 3600,  # Ø³Ø§Ø¹Ø© ÙˆØ§Ø­Ø¯Ø©
            "eviction_threshold": 0.8,  # 80% Ù…Ù† Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ù‚ØµÙ‰
            "cleanup_interval_seconds": 300,  # 5 Ø¯Ù‚Ø§Ø¦Ù‚
            "memory_monitoring": True,
            "adaptive_sizing": True
        }
        
        # Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ù†Ø¸Ø§Ù…
        self.stats = CacheStats(0, 0, 0.0, 0.0, 0, 0.0, 0.0)
        self.hit_count = 0
        self.miss_count = 0
        
        # Ø³ÙŠØ§Ø³Ø§Øª Ø§Ù„Ø¥Ø²Ø§Ù„Ø© Ù„ÙƒÙ„ Ù†ÙˆØ¹
        self.eviction_policies = {
            CacheType.PATTERN_CACHE: EvictionPolicy.LRU,
            CacheType.RESPONSE_CACHE: EvictionPolicy.TTL,
            CacheType.CONTEXT_CACHE: EvictionPolicy.LRU,
            CacheType.LEARNING_CACHE: EvictionPolicy.LFU,
            CacheType.METRICS_CACHE: EvictionPolicy.SIZE_BASED
        }
        
        # Ø®ÙˆØ§Ø±Ø²Ù…ÙŠØ§Øª Ø§Ù„Ø¥Ø¯Ø§Ø±Ø©
        self.size_calculator = SizeCalculator()
        self.eviction_manager = EvictionManager()
        self.memory_monitor = MemoryMonitor()
        self.performance_optimizer = PerformanceOptimizer()
        
        # Ø¨Ø¯Ø¡ Ø§Ù„Ù…Ù‡Ø§Ù… Ø§Ù„Ø®Ù„ÙÙŠØ©
        self.cleanup_task = None
        self.monitoring_task = None
        
        logger.info("ğŸ’¾ Advanced Cache Manager initialized")
    
    async def initialize(self):
        """ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ù†Ø¸Ø§Ù…"""
        # Ø¨Ø¯Ø¡ Ù…Ù‡Ù…Ø© Ø§Ù„ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø¯ÙˆØ±ÙŠ
        self.cleanup_task = asyncio.create_task(self._periodic_cleanup())
        
        # Ø¨Ø¯Ø¡ Ù…Ø±Ø§Ù‚Ø¨Ø© Ø§Ù„Ø°Ø§ÙƒØ±Ø©
        if self.config["memory_monitoring"]:
            self.monitoring_task = asyncio.create_task(self._memory_monitoring())
        
        logger.info("âœ… Cache Manager initialized and running")
    
    async def get(self, key: str, cache_type: CacheType) -> Optional[Any]:
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù‚ÙŠÙ…Ø© Ù…Ù† Ø§Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù…Ø¤Ù‚Øª"""
        try:
            cache = self.caches[cache_type]
            
            if key in cache:
                entry = cache[key]
                
                # ÙØ­Øµ Ø§Ù†ØªÙ‡Ø§Ø¡ Ø§Ù„ØµÙ„Ø§Ø­ÙŠØ©
                if self._is_expired(entry):
                    await self._remove_entry(key, cache_type)
                    self.miss_count += 1
                    return None
                
                # ØªØ­Ø¯ÙŠØ« Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„ÙˆØµÙˆÙ„
                entry.last_accessed = datetime.now()
                entry.access_count += 1
                
                self.hit_count += 1
                await self._update_stats()
                
                logger.debug(f"âœ… Cache hit: {key} from {cache_type.value}")
                return entry.value
            else:
                self.miss_count += 1
                await self._update_stats()
                
                logger.debug(f"âŒ Cache miss: {key} from {cache_type.value}")
                return None
                
        except Exception as e:
            logger.error(f"âŒ Error getting from cache: {e}")
            return None
    
    async def set(self, key: str, value: Any, cache_type: CacheType, 
                 ttl_seconds: Optional[int] = None, priority: float = 1.0) -> bool:
        """Ø¥Ø¶Ø§ÙØ© Ù‚ÙŠÙ…Ø© Ø¥Ù„Ù‰ Ø§Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù…Ø¤Ù‚Øª"""
        try:
            # Ø­Ø³Ø§Ø¨ Ø­Ø¬Ù… Ø§Ù„Ù‚ÙŠÙ…Ø©
            size_bytes = await self.size_calculator.calculate_size(value)
            
            # Ø¥Ù†Ø´Ø§Ø¡ Ø¥Ø¯Ø®Ø§Ù„ Ø¬Ø¯ÙŠØ¯
            entry = CacheEntry(
                key=key,
                value=value,
                cache_type=cache_type,
                created_at=datetime.now(),
                last_accessed=datetime.now(),
                size_bytes=size_bytes,
                ttl_seconds=ttl_seconds or self.config["default_ttl_seconds"],
                priority=priority,
                metadata={"created_by": "cache_manager"}
            )
            
            # ÙØ­Øµ Ø§Ù„Ù…Ø³Ø§Ø­Ø© Ø§Ù„Ù…ØªØ§Ø­Ø©
            if not await self._has_space_for_entry(entry):
                await self._evict_if_needed(cache_type)
            
            # Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„
            self.caches[cache_type][key] = entry
            
            await self._update_stats()
            
            logger.debug(f"ğŸ’¾ Cached: {key} in {cache_type.value} ({size_bytes} bytes)")
            return True
            
        except Exception as e:
            logger.error(f"âŒ Error setting cache: {e}")
            return False
    
    async def delete(self, key: str, cache_type: CacheType) -> bool:
        """Ø­Ø°Ù Ø¥Ø¯Ø®Ø§Ù„ Ù…Ù† Ø§Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù…Ø¤Ù‚Øª"""
        try:
            if key in self.caches[cache_type]:
                await self._remove_entry(key, cache_type)
                await self._update_stats()
                logger.debug(f"ğŸ—‘ï¸ Deleted: {key} from {cache_type.value}")
                return True
            return False
            
        except Exception as e:
            logger.error(f"âŒ Error deleting from cache: {e}")
            return False
    
    async def clear(self, cache_type: Optional[CacheType] = None) -> int:
        """Ù…Ø³Ø­ Ø§Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù…Ø¤Ù‚Øª"""
        try:
            cleared_count = 0
            
            if cache_type:
                cleared_count = len(self.caches[cache_type])
                self.caches[cache_type].clear()
            else:
                for cache in self.caches.values():
                    cleared_count += len(cache)
                    cache.clear()
            
            await self._update_stats()
            logger.info(f"ğŸ§¹ Cleared {cleared_count} entries from cache")
            return cleared_count
            
        except Exception as e:
            logger.error(f"âŒ Error clearing cache: {e}")
            return 0
    
    async def _is_expired(self, entry: CacheEntry) -> bool:
        """ÙØ­Øµ Ø§Ù†ØªÙ‡Ø§Ø¡ ØµÙ„Ø§Ø­ÙŠØ© Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„"""
        if entry.ttl_seconds is None:
            return False
        
        expiry_time = entry.created_at + timedelta(seconds=entry.ttl_seconds)
        return datetime.now() > expiry_time
    
    async def _has_space_for_entry(self, entry: CacheEntry) -> bool:
        """ÙØ­Øµ ØªÙˆÙØ± Ø§Ù„Ù…Ø³Ø§Ø­Ø© Ù„Ù„Ø¥Ø¯Ø®Ø§Ù„"""
        current_size = self.stats.total_size_bytes
        max_size = self.config["max_total_size_mb"] * 1024 * 1024
        
        return (current_size + entry.size_bytes) <= max_size
    
    async def _evict_if_needed(self, cache_type: CacheType):
        """Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„Ø§Øª Ø¹Ù†Ø¯ Ø§Ù„Ø­Ø§Ø¬Ø©"""
        cache = self.caches[cache_type]
        
        # ÙØ­Øµ Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ù‚ØµÙ‰ Ù„Ù„Ø¥Ø¯Ø®Ø§Ù„Ø§Øª
        if len(cache) >= self.config["max_entries_per_cache"]:
            await self._evict_entries(cache_type, 1)
        
        # ÙØ­Øµ Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ù‚ØµÙ‰ Ù„Ù„Ø­Ø¬Ù…
        current_size = sum(entry.size_bytes for entry in cache.values())
        max_size = self.config["max_total_size_mb"] * 1024 * 1024
        
        if current_size >= max_size * self.config["eviction_threshold"]:
            entries_to_evict = max(1, len(cache) // 10)  # Ø¥Ø²Ø§Ù„Ø© 10%
            await self._evict_entries(cache_type, entries_to_evict)
    
    async def _evict_entries(self, cache_type: CacheType, count: int):
        """Ø¥Ø²Ø§Ù„Ø© Ø¥Ø¯Ø®Ø§Ù„Ø§Øª Ù…Ø­Ø¯Ø¯Ø©"""
        cache = self.caches[cache_type]
        policy = self.eviction_policies[cache_type]
        
        entries_to_evict = await self.eviction_manager.select_entries_for_eviction(
            cache, policy, count
        )
        
        for key in entries_to_evict:
            await self._remove_entry(key, cache_type)
            self.stats.eviction_count += 1
        
        logger.info(f"ğŸ—‘ï¸ Evicted {len(entries_to_evict)} entries from {cache_type.value}")
    
    async def _remove_entry(self, key: str, cache_type: CacheType):
        """Ø¥Ø²Ø§Ù„Ø© Ø¥Ø¯Ø®Ø§Ù„ Ù…Ø­Ø¯Ø¯"""
        if key in self.caches[cache_type]:
            del self.caches[cache_type][key]
    
    async def _update_stats(self):
        """ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª"""
        self.stats.total_entries = sum(len(cache) for cache in self.caches.values())
        self.stats.total_size_bytes = sum(
            sum(entry.size_bytes for entry in cache.values())
            for cache in self.caches.values()
        )
        
        total_requests = self.hit_count + self.miss_count
        if total_requests > 0:
            self.stats.hit_rate = self.hit_count / total_requests
            self.stats.miss_rate = self.miss_count / total_requests
        
        # Ø­Ø³Ø§Ø¨ ÙƒÙØ§Ø¡Ø© Ø§Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù…Ø¤Ù‚Øª
        self.stats.cache_efficiency = self.stats.hit_rate * (1 - self.stats.miss_rate)
    
    async def _periodic_cleanup(self):
        """ØªÙ†Ø¸ÙŠÙ Ø¯ÙˆØ±ÙŠ Ù„Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù…Ø¤Ù‚Øª"""
        while True:
            try:
                await asyncio.sleep(self.config["cleanup_interval_seconds"])
                
                # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„Ø§Øª Ø§Ù„Ù…Ù†ØªÙ‡ÙŠØ© Ø§Ù„ØµÙ„Ø§Ø­ÙŠØ©
                expired_count = 0
                for cache_type, cache in self.caches.items():
                    expired_keys = [
                        key for key, entry in cache.items()
                        if await self._is_expired(entry)
                    ]
                    
                    for key in expired_keys:
                        await self._remove_entry(key, cache_type)
                        expired_count += 1
                
                if expired_count > 0:
                    logger.info(f"ğŸ§¹ Cleaned up {expired_count} expired entries")
                
                # ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø£Ø¯Ø§Ø¡
                await self.performance_optimizer.optimize_caches(self.caches)
                
            except Exception as e:
                logger.error(f"âŒ Error in periodic cleanup: {e}")
    
    async def _memory_monitoring(self):
        """Ù…Ø±Ø§Ù‚Ø¨Ø© Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø°Ø§ÙƒØ±Ø©"""
        while True:
            try:
                await asyncio.sleep(60)  # ÙƒÙ„ Ø¯Ù‚ÙŠÙ‚Ø©
                
                # Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø°Ø§ÙƒØ±Ø©
                memory_info = psutil.virtual_memory()
                self.stats.memory_usage_percent = memory_info.percent
                
                # ØªØ­Ø°ÙŠØ± Ø¹Ù†Ø¯ Ø§Ø±ØªÙØ§Ø¹ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø°Ø§ÙƒØ±Ø©
                if memory_info.percent > 85:
                    logger.warning(f"âš ï¸ High memory usage: {memory_info.percent:.1f}%")
                    
                    # ØªÙ†Ø¸ÙŠÙ Ø¥Ø¶Ø§ÙÙŠ Ø¹Ù†Ø¯ Ø§Ø±ØªÙØ§Ø¹ Ø§Ù„Ø°Ø§ÙƒØ±Ø©
                    await self._emergency_cleanup()
                
            except Exception as e:
                logger.error(f"âŒ Error in memory monitoring: {e}")
    
    async def _emergency_cleanup(self):
        """ØªÙ†Ø¸ÙŠÙ Ø·Ø§Ø±Ø¦ Ø¹Ù†Ø¯ Ø§Ø±ØªÙØ§Ø¹ Ø§Ù„Ø°Ø§ÙƒØ±Ø©"""
        logger.warning("ğŸš¨ Emergency cache cleanup initiated")
        
        # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„Ø§Øª Ù…Ù†Ø®ÙØ¶Ø© Ø§Ù„Ø£ÙˆÙ„ÙˆÙŠØ©
        for cache_type, cache in self.caches.items():
            low_priority_entries = [
                (key, entry) for key, entry in cache.items()
                if entry.priority < 0.5
            ]
            
            # ØªØ±ØªÙŠØ¨ Ø­Ø³Ø¨ Ø§Ù„Ø£ÙˆÙ„ÙˆÙŠØ© ÙˆØ§Ù„ÙˆØµÙˆÙ„ Ø§Ù„Ø£Ø®ÙŠØ±
            low_priority_entries.sort(key=lambda x: (x[1].priority, x[1].last_accessed))
            
            # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ù†ØµÙ Ø§Ù„Ø£Ù‚Ù„ Ø£ÙˆÙ„ÙˆÙŠØ©
            entries_to_remove = low_priority_entries[:len(low_priority_entries)//2]
            
            for key, _ in entries_to_remove:
                await self._remove_entry(key, cache_type)
        
        await self._update_stats()
        logger.info("âœ… Emergency cleanup completed")
    
    async def get_cache_analytics(self) -> Dict[str, Any]:
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ ØªØ­Ù„ÙŠÙ„Ø§Øª Ø§Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù…Ø¤Ù‚Øª"""
        analytics = {
            "overall_stats": self.stats.__dict__,
            "cache_types": {},
            "memory_info": {
                "total_size_mb": self.stats.total_size_bytes / (1024 * 1024),
                "memory_usage_percent": self.stats.memory_usage_percent,
                "available_memory_mb": psutil.virtual_memory().available / (1024 * 1024)
            },
            "performance_metrics": {
                "hit_rate": self.stats.hit_rate,
                "miss_rate": self.stats.miss_rate,
                "efficiency": self.stats.cache_efficiency,
                "eviction_rate": self.stats.eviction_count / max(1, self.stats.total_entries)
            },
            "timestamp": datetime.now().isoformat()
        }
        
        # Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª ÙƒÙ„ Ù†ÙˆØ¹ ØªØ®Ø²ÙŠÙ† Ù…Ø¤Ù‚Øª
        for cache_type, cache in self.caches.items():
            analytics["cache_types"][cache_type.value] = {
                "entry_count": len(cache),
                "total_size_bytes": sum(entry.size_bytes for entry in cache.values()),
                "avg_entry_size": np.mean([entry.size_bytes for entry in cache.values()]) if cache else 0,
                "eviction_policy": self.eviction_policies[cache_type].value,
                "oldest_entry": min([entry.created_at for entry in cache.values()]).isoformat() if cache else None,
                "newest_entry": max([entry.created_at for entry in cache.values()]).isoformat() if cache else None
            }
        
        return analytics

class SizeCalculator:
    """Ø­Ø§Ø³Ø¨Ø© Ø§Ù„Ø­Ø¬Ù…"""
    
    async def calculate_size(self, value: Any) -> int:
        """Ø­Ø³Ø§Ø¨ Ø­Ø¬Ù… Ø§Ù„Ù‚ÙŠÙ…Ø© Ø¨Ø§Ù„Ø¨Ø§ÙŠØª"""
        try:
            if isinstance(value, str):
                return len(value.encode('utf-8'))
            elif isinstance(value, (int, float)):
                return 8  # ØªÙ‚Ø¯ÙŠØ± ØªÙ‚Ø±ÙŠØ¨ÙŠ
            elif isinstance(value, dict):
                return len(json.dumps(value, default=str).encode('utf-8'))
            elif isinstance(value, list):
                return sum(await self.calculate_size(item) for item in value)
            else:
                return len(str(value).encode('utf-8'))
        except Exception:
            return 1024  # Ø­Ø¬Ù… Ø§ÙØªØ±Ø§Ø¶ÙŠ

class EvictionManager:
    """Ù…Ø¯ÙŠØ± Ø§Ù„Ø¥Ø²Ø§Ù„Ø©"""
    
    async def select_entries_for_eviction(self, cache: Dict[str, CacheEntry], 
                                        policy: EvictionPolicy, count: int) -> List[str]:
        """Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„Ø§Øª Ù„Ù„Ø¥Ø²Ø§Ù„Ø©"""
        if len(cache) <= count:
            return list(cache.keys())
        
        if policy == EvictionPolicy.LRU:
            return self._select_lru(cache, count)
        elif policy == EvictionPolicy.LFU:
            return self._select_lfu(cache, count)
        elif policy == EvictionPolicy.TTL:
            return self._select_by_ttl(cache, count)
        elif policy == EvictionPolicy.SIZE_BASED:
            return self._select_by_size(cache, count)
        else:  # ADAPTIVE
            return self._select_adaptive(cache, count)
    
    def _select_lru(self, cache: Dict[str, CacheEntry], count: int) -> List[str]:
        """Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ø£Ù‚Ù„ Ø§Ø³ØªØ®Ø¯Ø§Ù…Ù‹Ø§ Ù…Ø¤Ø®Ø±Ù‹Ø§"""
        sorted_entries = sorted(
            cache.items(),
            key=lambda x: x[1].last_accessed
        )
        return [key for key, _ in sorted_entries[:count]]
    
    def _select_lfu(self, cache: Dict[str, CacheEntry], count: int) -> List[str]:
        """Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ø£Ù‚Ù„ Ø§Ø³ØªØ®Ø¯Ø§Ù…Ù‹Ø§"""
        sorted_entries = sorted(
            cache.items(),
            key=lambda x: x[1].access_count
        )
        return [key for key, _ in sorted_entries[:count]]
    
    def _select_by_ttl(self, cache: Dict[str, CacheEntry], count: int) -> List[str]:
        """Ø§Ø®ØªÙŠØ§Ø± Ø­Ø³Ø¨ Ø§Ù†ØªÙ‡Ø§Ø¡ Ø§Ù„ØµÙ„Ø§Ø­ÙŠØ©"""
        sorted_entries = sorted(
            cache.items(),
            key=lambda x: x[1].created_at + timedelta(seconds=x[1].ttl_seconds or 0)
        )
        return [key for key, _ in sorted_entries[:count]]
    
    def _select_by_size(self, cache: Dict[str, CacheEntry], count: int) -> List[str]:
        """Ø§Ø®ØªÙŠØ§Ø± Ø­Ø³Ø¨ Ø§Ù„Ø­Ø¬Ù…"""
        sorted_entries = sorted(
            cache.items(),
            key=lambda x: x[1].size_bytes,
            reverse=True
        )
        return [key for key, _ in sorted_entries[:count]]
    
    def _select_adaptive(self, cache: Dict[str, CacheEntry], count: int) -> List[str]:
        """Ø§Ø®ØªÙŠØ§Ø± ØªÙƒÙŠÙÙŠ"""
        # Ø¯Ù…Ø¬ Ø¹Ø¯Ø© Ø¹ÙˆØ§Ù…Ù„
        scored_entries = []
        
        for key, entry in cache.items():
            score = (
                entry.access_count * 0.3 +  # ØªÙƒØ±Ø§Ø± Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…
                (datetime.now() - entry.last_accessed).total_seconds() * 0.4 +  # Ø§Ù„ÙˆÙ‚Øª Ù…Ù†Ø° Ø¢Ø®Ø± Ø§Ø³ØªØ®Ø¯Ø§Ù…
                entry.size_bytes * 0.2 +  # Ø§Ù„Ø­Ø¬Ù…
                (1 - entry.priority) * 0.1  # Ø§Ù„Ø£ÙˆÙ„ÙˆÙŠØ©
            )
            scored_entries.append((key, score))
        
        scored_entries.sort(key=lambda x: x[1], reverse=True)
        return [key for key, _ in scored_entries[:count]]

class MemoryMonitor:
    """Ù…Ø±Ø§Ù‚Ø¨ Ø§Ù„Ø°Ø§ÙƒØ±Ø©"""
    
    def __init__(self):
        self.memory_history = deque(maxlen=100)
    
    async def get_memory_usage(self) -> Dict[str, float]:
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø°Ø§ÙƒØ±Ø©"""
        memory_info = psutil.virtual_memory()
        
        return {
            "total_mb": memory_info.total / (1024 * 1024),
            "available_mb": memory_info.available / (1024 * 1024),
            "used_percent": memory_info.percent,
            "cached_mb": memory_info.cached / (1024 * 1024) if hasattr(memory_info, 'cached') else 0
        }

class PerformanceOptimizer:
    """Ù…Ø­Ø³Ù† Ø§Ù„Ø£Ø¯Ø§Ø¡"""
    
    async def optimize_caches(self, caches: Dict[CacheType, Dict[str, CacheEntry]]):
        """ØªØ­Ø³ÙŠÙ† Ø£Ø¯Ø§Ø¡ Ø§Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù…Ø¤Ù‚Øª"""
        for cache_type, cache in caches.items():
            # ØªØ­Ø³ÙŠÙ† ØªØ±ØªÙŠØ¨ Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„Ø§Øª Ø­Ø³Ø¨ Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…
            await self._optimize_access_patterns(cache)
            
            # Ø¶ØºØ· Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¥Ø°Ø§ Ø£Ù…ÙƒÙ†
            await self._compress_large_entries(cache)
    
    async def _optimize_access_patterns(self, cache: Dict[str, CacheEntry]):
        """ØªØ­Ø³ÙŠÙ† Ø£Ù†Ù…Ø§Ø· Ø§Ù„ÙˆØµÙˆÙ„"""
        # Ø¥Ø¹Ø§Ø¯Ø© ØªØ±ØªÙŠØ¨ Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„Ø§Øª Ø­Ø³Ø¨ ØªÙƒØ±Ø§Ø± Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…
        pass  # ÙŠÙ…ÙƒÙ† ØªØ·Ø¨ÙŠÙ‚ Ø®ÙˆØ§Ø±Ø²Ù…ÙŠØ§Øª ØªØ­Ø³ÙŠÙ† Ù…ØªÙ‚Ø¯Ù…Ø©
    
    async def _compress_large_entries(self, cache: Dict[str, CacheEntry]):
        """Ø¶ØºØ· Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„Ø§Øª Ø§Ù„ÙƒØ¨ÙŠØ±Ø©"""
        # Ø¶ØºØ· Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„Ø§Øª Ø§Ù„ØªÙŠ ØªØªØ¬Ø§ÙˆØ² Ø­Ø¬Ù… Ù…Ø¹ÙŠÙ†
        pass  # ÙŠÙ…ÙƒÙ† ØªØ·Ø¨ÙŠÙ‚ Ø¶ØºØ· Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª

# Ù…Ø«Ø§Ù„ Ø¹Ù„Ù‰ Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…
async def demo_cache_manager():
    """Ø¹Ø±Ø¶ ØªÙˆØ¶ÙŠØ­ÙŠ Ù„Ù…Ø¯ÙŠØ± Ø§Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù…Ø¤Ù‚Øª"""
    print("ğŸ’¾ Advanced Cache Manager Demo")
    print("=" * 50)
    
    cache_manager = AdvancedCacheManager()
    await cache_manager.initialize()
    
    # Ø§Ø®ØªØ¨Ø§Ø± Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
    test_data = [
        ("pattern_001", {"type": "help_request", "confidence": 0.9}, CacheType.PATTERN_CACHE),
        ("response_001", "This is a helpful response", CacheType.RESPONSE_CACHE),
        ("context_001", {"user_level": "beginner", "platform": "macOS"}, CacheType.CONTEXT_CACHE),
        ("learning_001", {"accuracy": 0.85, "patterns": 45}, CacheType.LEARNING_CACHE),
        ("metrics_001", {"hit_rate": 0.92, "response_time": 156}, CacheType.METRICS_CACHE)
    ]
    
    print("\nğŸ“ Adding test data to cache...")
    for key, value, cache_type in test_data:
        success = await cache_manager.set(key, value, cache_type)
        print(f"   {key} -> {cache_type.value}: {'âœ…' if success else 'âŒ'}")
    
    # Ø§Ø®ØªØ¨Ø§Ø± Ø§Ø³ØªØ±Ø¬Ø§Ø¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
    print("\nğŸ” Retrieving data from cache...")
    for key, _, cache_type in test_data:
        value = await cache_manager.get(key, cache_type)
        print(f"   {key} from {cache_type.value}: {'âœ…' if value else 'âŒ'}")
    
    # Ø¹Ø±Ø¶ Ø§Ù„ØªØ­Ù„ÙŠÙ„Ø§Øª
    print("\nğŸ“Š Cache Analytics:")
    analytics = await cache_manager.get_cache_analytics()
    
    print(f"   Total Entries: {analytics['overall_stats']['total_entries']}")
    print(f"   Total Size: {analytics['overall_stats']['total_size_bytes']} bytes")
    print(f"   Hit Rate: {analytics['overall_stats']['hit_rate']:.3f}")
    print(f"   Memory Usage: {analytics['memory_info']['memory_usage_percent']:.1f}%")
    
    # ØªÙ†Ø¸ÙŠÙ
    await cache_manager.clear()
    print("\nğŸ§¹ Cache cleared")

if __name__ == "__main__":
    asyncio.run(demo_cache_manager())
